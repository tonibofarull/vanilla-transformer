# Vanilla Transformer

PyTorch implementation of the original transformer paper ([Vaswani et al.](https://arxiv.org/abs/1706.03762)).

<br>
<div align="center">
    <img src="utils/assets/model.png" width="50%"/>
</div>
<br>

## TODO

- Learning rate Scheduler: We are using ADAM with a learning rate of 0.0001.
- Train and test model in a real dataset. We tested the model with the toy corpus to see that the model can overfit. (Problem: GPU ðŸ˜”)
