{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from models.transformer import Transformer\r\n",
    "from dataloader import EnglishSpanish\r\n",
    "from train import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus src: 12\n",
      "Corpus tgt: 13\n"
     ]
    }
   ],
   "source": [
    "data = EnglishSpanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = Transformer(data.voc_src_len, data.voc_tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1 | loss: 0.9108041524887085\n",
      "EPOCH 1 train loss: 0.9108041524887085\n",
      "\n",
      "0/1 | loss: 0.7191761136054993\n",
      "EPOCH 2 train loss: 0.7191761136054993\n",
      "\n",
      "0/1 | loss: 0.6274900436401367\n",
      "EPOCH 3 train loss: 0.6274900436401367\n",
      "\n",
      "0/1 | loss: 0.5647739768028259\n",
      "EPOCH 4 train loss: 0.5647739768028259\n",
      "\n",
      "0/1 | loss: 0.509441077709198\n",
      "EPOCH 5 train loss: 0.509441077709198\n",
      "\n",
      "0/1 | loss: 0.4431358873844147\n",
      "EPOCH 6 train loss: 0.4431358873844147\n",
      "\n",
      "0/1 | loss: 0.38381922245025635\n",
      "EPOCH 7 train loss: 0.38381922245025635\n",
      "\n",
      "0/1 | loss: 0.33484014868736267\n",
      "EPOCH 8 train loss: 0.33484014868736267\n",
      "\n",
      "0/1 | loss: 0.2945493459701538\n",
      "EPOCH 9 train loss: 0.2945493459701538\n",
      "\n",
      "0/1 | loss: 0.26122957468032837\n",
      "EPOCH 10 train loss: 0.26122957468032837\n",
      "\n",
      "0/1 | loss: 0.23324202001094818\n",
      "EPOCH 11 train loss: 0.23324202001094818\n",
      "\n",
      "0/1 | loss: 0.21175462007522583\n",
      "EPOCH 12 train loss: 0.21175462007522583\n",
      "\n",
      "0/1 | loss: 0.19159573316574097\n",
      "EPOCH 13 train loss: 0.19159573316574097\n",
      "\n",
      "0/1 | loss: 0.17370697855949402\n",
      "EPOCH 14 train loss: 0.17370697855949402\n",
      "\n",
      "0/1 | loss: 0.1594718098640442\n",
      "EPOCH 15 train loss: 0.1594718098640442\n",
      "\n",
      "0/1 | loss: 0.1458619385957718\n",
      "EPOCH 16 train loss: 0.1458619385957718\n",
      "\n",
      "0/1 | loss: 0.13367362320423126\n",
      "EPOCH 17 train loss: 0.13367362320423126\n",
      "\n",
      "0/1 | loss: 0.12368611246347427\n",
      "EPOCH 18 train loss: 0.12368611246347427\n",
      "\n",
      "0/1 | loss: 0.1150190606713295\n",
      "EPOCH 19 train loss: 0.1150190606713295\n",
      "\n",
      "0/1 | loss: 0.10735169053077698\n",
      "EPOCH 20 train loss: 0.10735169053077698\n",
      "\n",
      "Training Finished in 13.274998426437378s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(iters=20)\r\n",
    "_, _ = trainer.fit(tm, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"ey! hola\"\r\n",
    "sentence = data._tokenize_es(sentence)\r\n",
    "inp_pad = data.MAX_LEN - len(sentence)\r\n",
    "sentence = sentence + [\"<PAD>\"] * inp_pad\r\n",
    "inp = data._token_to_idx(sentence).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = iter(DataLoader(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hola', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']]\n",
      "[['hi', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']]\n"
     ]
    }
   ],
   "source": [
    "inp, out, inp_pad, out_pad, src, tgt = next(dl)\r\n",
    "print(data._idx_to_token(inp, is_src=True))\r\n",
    "print(data._idx_to_token(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "[['<SOS>']]\n"
     ]
    }
   ],
   "source": [
    "tm.eval()\r\n",
    "sos = torch.repeat_interleave(data.sos, 1, 0)\r\n",
    "out1 = torch.cat([sos], 1)\r\n",
    "print(out1)\r\n",
    "print(data._idx_to_token(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top best values:\n",
      "[('<EOS>', 0.9490163), ('hi', 0.0110339485), ('!', 0.008259185), (',', 0.008106744), ('<PAD>', 0.004780334)]\n",
      "\n",
      "Current output:\n",
      "[['<SOS>', 'hi', '<EOS>']]\n"
     ]
    }
   ],
   "source": [
    "PICK_TOP = 0\r\n",
    "\r\n",
    "R = tm(inp, out1, inp_pad, [0])\r\n",
    "last_pred = R[0,-1]\r\n",
    "values, indices = torch.topk(last_pred, k=5)\r\n",
    "probs = values.detach().numpy()\r\n",
    "r = torch.tensor([indices[PICK_TOP]])\r\n",
    "out1 = torch.cat([out1, r.reshape(1, 1)], 1)\r\n",
    "print(\"Top best values:\")\r\n",
    "print([(data.voc_tgt[x], p) for x, p in zip(indices, probs)])\r\n",
    "print()\r\n",
    "print(\"Current output:\")\r\n",
    "print(data._idx_to_token(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db019ecaa3c28c44b8b78b540e02daf540360ff12e3512a6df42e6c69ce06a44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc92e22c73eaa7c4f99e353a9a6142b69d86713b39a02875a370276bee564234"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}