{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.nn import functional as F\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from models.transformer import Transformer\r\n",
    "from train import Trainer\r\n",
    "from dataloader import EnglishToSpanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = EnglishToSpanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = Transformer(data.voc_src_len, data.voc_tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\r\n",
    "_, _ = trainer.fit(tm, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"ey! hola\"\r\n",
    "sentence = data._tokenize_es(sentence)\r\n",
    "inp_pad = data.MAX_LEN - len(sentence)\r\n",
    "sentence = sentence + [\"<PAD>\"] * inp_pad\r\n",
    "inp = data._token_to_idx(sentence).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = iter(DataLoader(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, out, inp_pad, out_pad, src, tgt = next(dl)\r\n",
    "print(data._idx_to_token(inp, is_src=True))\r\n",
    "print(data._idx_to_token(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.eval()\r\n",
    "sos = torch.repeat_interleave(data.sos, 1, 0)\r\n",
    "out1 = torch.cat([sos], 1)\r\n",
    "print(out1)\r\n",
    "print(data._idx_to_token(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICK_TOP = 0\r\n",
    "\r\n",
    "R = tm(inp, out1, inp_pad, 0)\r\n",
    "last_pred = R[0,-1]\r\n",
    "values, indices = torch.topk(last_pred, k=2)\r\n",
    "r = torch.tensor([indices[PICK_TOP]])\r\n",
    "out1 = torch.cat([out1, r.reshape(1, 1)], 1)\r\n",
    "print(f\"Adding with prob. {values[PICK_TOP]}\")\r\n",
    "print(out1)\r\n",
    "print(data._idx_to_token(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.voc_tgt)\r\n",
    "print(last_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db019ecaa3c28c44b8b78b540e02daf540360ff12e3512a6df42e6c69ce06a44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc92e22c73eaa7c4f99e353a9a6142b69d86713b39a02875a370276bee564234"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}